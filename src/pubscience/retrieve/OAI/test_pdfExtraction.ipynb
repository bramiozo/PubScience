{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pdf and extract text\n",
    "# We want to ignore all the decorum and only extract the text (i.e. no page number etc.)\n",
    "import pytesseract\n",
    "from PyPDF2 import PdfReader\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import fitz\n",
    "from PIL import Image\n",
    "\n",
    "from io import StringIO\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '//Ds/data/LAB/laupodteam/AIOS/Bram/language_modeling/MEDICAL_TEXT/RAW/PhDTheses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(path, backends=['pypdf', 'fitz']):\n",
    "    '''Extract text from pdf documents\n",
    "        Source: https://towardsdatascience.com/pdf-preprocessing-with-python-19829752af9f\n",
    "    '''\n",
    "    def pdfminer(_path):\n",
    "        manager = PDFResourceManager()\n",
    "        retstr = StringIO()\n",
    "        layout = LAParams(all_texts=False, detect_vertical=True)\n",
    "        device = TextConverter(manager, retstr, laparams=layout)\n",
    "        interpreter = PDFPageInterpreter(manager, device)\n",
    "        with open(_path, 'rb') as filepath:\n",
    "            for page in PDFPage.get_pages(filepath, check_extractable=True):\n",
    "                interpreter.process_page(page)\n",
    "        text = retstr.getvalue()\n",
    "        device.close()\n",
    "        retstr.close()\n",
    "        return text\n",
    "\n",
    "    def pypdfer(_path):\n",
    "        reader = PdfReader(_path)\n",
    "        return [p.extract_text(0) for p in reader.pages]\n",
    "    \n",
    "    error = \"\"\n",
    "\n",
    "    if 'pypdf' in backends:\n",
    "        try:\n",
    "            return pypdfer(path), None\n",
    "        except Exception as e_1:\n",
    "            error = error + f\"\\n PyPDF failed: {e_1}\"\n",
    "   \n",
    "    if 'fitz' in backends:\n",
    "        try:\n",
    "            pdf_file = fitz.open(path)\n",
    "            pages = []\n",
    "            for _p in pdf_file:\n",
    "                pages.append(_p.getText())\n",
    "            return pages, error\n",
    "        except Exception as e_2:\n",
    "            error = error + f\"\\n PyMuPDF failed: {e_2}\"\n",
    "        \n",
    "    if 'pdfminer' in backends:\n",
    "        try:\n",
    "            return pdfminer(path), None\n",
    "        except Exception as e_3:\n",
    "            error = error + f\"pdfminer failed: {e_3}\"\n",
    "\n",
    "    if 'pytesseract' in backends:\n",
    "        try:\n",
    "            return pytesseract.image_to_string(path, lang='en'), None\n",
    "        except Exception as e_4:\n",
    "            return error + f\"\\n PyTesseract failed: {e_4}\" \n",
    "        \n",
    "# https://arxiv.org/abs/2308.13418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Files = [f for f in os.listdir(pdf_path) if f.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n"
     ]
    }
   ],
   "source": [
    "_File = 'Radboud_47910.pdf' # Files[245]\n",
    "_path = os.path.join(pdf_path, _File)\n",
    "Text, error = pdf_to_text(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nums_samenvatting = [i for i,p in enumerate(Text) if 'samenvatting' in p.lower()]\n",
    "page_nums_dankwoord = [i for i,p in enumerate(Text) if any([t in p.lower() for t in ['dankwoord', 'nawoord']])]\n",
    "page_nums_empty = [i for i,p in enumerate(Text) if p.strip()=='']\n",
    "page_nums_ToC = [i for i,p in enumerate(Text) if 'content' in p.lower()]\n",
    "print(page_nums_samenvatting, page_nums_dankwoord, page_nums_empty, page_nums_ToC, _File)\n",
    "# extract the text from the pdfs based on the page_nums:\n",
    "# if there is a page number, we assume that text on that page is relevant\n",
    "\n",
    "# then we want to find the delimiters for the different sections\n",
    "\n",
    "def get_samenvatting_page(txts, page_nums_ToC):\n",
    "    ToC_num = min([n for n in page_nums_ToC if n>1])\n",
    "    ToC_page = txts[ToC_num]\n",
    "    return int(re.findall(r'Samenvatting[\\s\\t]+(\\d+)', ToC_page))\n",
    "\n",
    "# first element in ToC, after the samenvatting\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
